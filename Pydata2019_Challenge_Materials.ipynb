{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pydata2019_Challenge_Materials.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK3qDmsgZbl8",
        "colab_type": "text"
      },
      "source": [
        "# PyData 2019 Deep Learning Workshop Challenge - Pipple & 510\n",
        "\n",
        "Before you start this challenge, make sure you save this notebook file to your own Google Drive and continue from the copied notebook.\n",
        "\n",
        "File -> Save a copy in Drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrDBsCrioC0C",
        "colab_type": "text"
      },
      "source": [
        "# Table of Contents\n",
        "\n",
        "\n",
        "1.   Problem Description\n",
        "2.   Retrieve data\n",
        "3.   Image Data Generators\n",
        "4.   Transfer Learning + Fine-Tuning a CNN (in Keras)\n",
        "5.   Training a CNN (in Keras)\n",
        "6.   Analysing Training Results\n",
        "7.   Submit your model!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnDsGsCzi-PJ",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "---\n",
        "# 1. Challenge Description\n",
        "\n",
        "Help Pipple & 510 be developing a CNN model that can classify roof materials, either concrete, metal or tiles, of individual buildings in Sint Maarten! By doing this you help 510 with their challenga of automating the classification of building characteristics within aerial imagery. Try to Ô¨Åne-tuning a CNN (i.e. either VGG16, Inception or Xception) on the target data set and make sure you submit your results! The team that achieves the highest accuracy on the 'never been seen' test set will recieve a wonderful Pipple prize! \n",
        "\n",
        "The challenge contest will be due on saturday 12:00 noon! All submitted CNN models will be evaluated by Pipple on the test set. \n",
        "\n",
        "Use the Pydata 2019 Deep Learning Workshop Tutorial as a guideline and be creative! And last but not least; ENJOY!\n",
        "\n",
        "Pipple and 510 look forward to your results! Good luck!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6YWu_6xoGw5",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# 2. Retrieve Data\n",
        "\n",
        "You will be fine-tuning your CNN on the train and validation set which can be retrieved by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bkYxvqyMZZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone -b materials https://github.com/PippleNL/pydata2019.git\n",
        "\n",
        "\n",
        "import zipfile\n",
        "\n",
        "for sets in ['train_materials', 'validation_materials']:\n",
        "\n",
        "  # path to zip\n",
        "  local_zip = f'pydata2019/{sets}.zip' \n",
        "\n",
        "  # extract zip file\n",
        "  zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "  zip_ref.extractall('/tmp')\n",
        "  zip_ref.close()\n",
        "\n",
        "import os\n",
        "\n",
        "base_dir = '/tmp/'\n",
        "\n",
        "# data directories\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptXtrvoYq6cb",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# 3. Image Data Generators\n",
        "\n",
        "In the cell below you can specify your own ImageDataGenerator specifications.\n",
        "For more information on Keras' ImageDataGenerators please visit <sup>[5](#myfootnote1)</sup> \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "><sup>[5](#myfootnote1)</sup> https://keras.io/preprocessing/image/#imagedatagenerator-class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CZJBz2YZ0Mb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import preprocess_input as preprocess_input_vgg16\n",
        "from keras.applications.inception_v3 import preprocess_input as preprocess_input_inception\n",
        "from keras.applications.xception import preprocess_input as preprocess_input_xception\n",
        "\n",
        "seed = 42  # Make the Image Data Generator objects reproducible\n",
        "\n",
        "def get_cnn_data_generators(cnn):\n",
        "  \"\"\"\n",
        "  Function that returns Image Data Generator objects for the train and validation set related to a pre-trained cnn (i.e. VGG16, Inception, Xception)\n",
        "  \"\"\"\n",
        "  # Different pre-trained CNN's have different images pre-processor functions\n",
        "  if cnn == 'vgg16':\n",
        "    pre_processor = preprocess_input_vgg16\n",
        "  elif cnn == 'inception':\n",
        "    pre_processor = preprocess_input_inception\n",
        "  elif cnn == 'xception':\n",
        "    pre_processor = preprocess_input_xception\n",
        "  else:\n",
        "    raise ValueError(f'Unknown pre-trained CNN. Got {cnn} whereas vgg16, inception or exception is expected.')\n",
        "\n",
        "\n",
        "  # Below Image Data Generator object is related to the train data set\n",
        "  train_datagen = ImageDataGenerator(\n",
        "    # Type here your (extra) Image Data Generator specifications\n",
        "    # For more information visit the link above\n",
        "  )\n",
        "\n",
        "\n",
        "  # Below Image Data Generator object is related to the validation set\n",
        "  val_datagen = ImageDataGenerator(\n",
        "      # Type here your (extra) Image Data Generator specifications\n",
        "  )\n",
        "\n",
        "  return train_datagen, val_datagen\n",
        "\n",
        "\n",
        "def get_image_batches(train_datagen, val_datagen, cnn):\n",
        "  \"\"\"\n",
        "  Takes the path to a directory & generates batches of (augmented) data reshaped to the desired input shape\n",
        "  \"\"\"\n",
        "  # Different pre-trained CNN's use different target images sizes as input \n",
        "  if cnn == 'vgg16':\n",
        "    target_size = (224, 224)  # All images will be resized to 224x224\n",
        "  elif cnn == 'inception':\n",
        "    target_size = (299, 299)  # All images will be resized to 299x99\n",
        "  elif cnn == 'xception':\n",
        "    target_size = (299, 299)  # All images will be resized to 299x299\n",
        "  else:\n",
        "    raise ValueError(f'Unknown pre-trained CNN. Got {cnn} whereas vgg16, inception or exception is expected.') \n",
        "\n",
        "\n",
        "  # Keras is able to directly augment and use images out of folders from the server's local file system using the flow_from_directory method\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "      # Type here your (extra) flow_from_directory specifications\n",
        "  )  \n",
        "\n",
        "\n",
        "  # Below examples uses the validation Image Data Generator to pre-process the images from the validation_dir (on the server's local file system)\n",
        "  validation_generator = val_datagen.flow_from_directory(\n",
        "    # Type here your (extra) flow_from_directory specifications\n",
        "  )  \n",
        "\n",
        "  return train_generator, validation_generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "890ETAOmsPkL",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# 4. Transfer Learning + Fine-Tuning a CNN (in Keras)\n",
        "\n",
        "In the cell below you can fine-tune a pre-trained CNN! This makes it usable for classifying roof shapes. In <sup>[6](#myfootnote1)</sup> and <sup>[7](#myfootnote1)</sup> one can find more information about pre-trained CNNs and Keras' core layers. \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "><sup>[6](#myfootnote1)</sup> https://pure.tue.nl/ws/portalfiles/portal/125083941/Master_Thesis_Bart_van_Driel.pdf\n",
        "\n",
        "> <sup>[7](#myfootnote1)</sup> https://keras.io/layers/core/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0lpg-vrHuhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")  # surpress library warnings\n",
        "\n",
        "\n",
        "def get_cnn_model(cnn):\n",
        "  \"\"\"\n",
        "  Retrieves the parameters and architecture of pre-trained CNNs (on ImageNet data) without the top (classification) layers.\n",
        "  It builds on top of these retrieve (feature extraction) layers a block of layers used for classification. \n",
        "  \"\"\"\n",
        "  # Retrieve the pre-trained cnn on images of imagenet without the top-classification layers\n",
        "  if cnn == 'vgg16':\n",
        "    base_model  = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "  elif cnn == 'inception':\n",
        "    base_model  = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        "  elif cnn == 'xception':\n",
        "    base_model  = Xception(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        "  else:\n",
        "    raise ValueError(f'Unknown pre-trained CNN. Got {cnn} whereas vgg16, inception or exception is expected.') \n",
        "\n",
        "  # Think about how many layers you want to train\n",
        "  # ...\n",
        "\n",
        "  # Add (and import) extra layers; end the classification block with a layer called preds\n",
        "  # ...\n",
        "  \n",
        "  # Build the model having non-trainable pre-trained feature extration layers and trainable classification layers\n",
        "  model = Model(inputs=base_model.input, outputs=preds)\n",
        "\n",
        "  # Optionally print model summary\n",
        "  # print(model.summary())\n",
        "\n",
        "  return model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSFw13iKwj2L",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "---\n",
        "## 5.   Training a CNN (in Keras)\n",
        "\n",
        "Train your model by running the cells below! Think about how you want your model to be compiled, which training results should be stored (i.e. callbacks) and which fitting parameters you prefer. \n",
        "\n",
        "More information about this can be found in <sup>[8](#myfootnote1)</sup>, <sup>[9](#myfootnote1)</sup>, <sup>[10](#myfootnote1)</sup>, <sup>[11](#myfootnote1)</sup> and <sup>[12](#myfootnote1)</sup>.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "><sup>[8](#myfootnote1)</sup> https://keras.io/models/sequential/\n",
        "\n",
        "><sup>[9](#myfootnote1)</sup> https://keras.io/losses/\n",
        "\n",
        "><sup>[10](#myfootnote1)</sup> https://keras.io/optimizers/\n",
        "\n",
        "><sup>[11](#myfootnote1)</sup> https://keras.io/metrics/\n",
        "\n",
        "><sup>[12](#myfootnote1)</sup> https://keras.io/callbacks/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-UHs13Mb-4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_compile_cnn(cnn):\n",
        "  \"\"\"\n",
        "  Builds a CNN architecture based on one of the three pre-trained CNNs (on ImageNet data) and extra added classification layers.\n",
        "  Compiles this built cnn by specifying a loss function, optimizer and evaluation metric.\n",
        "  \"\"\"\n",
        "\n",
        "  # Retrieve feature extraction layers of the pre-trained CNN and add newly to be trained (classification) layers\n",
        "  cnn_model = get_cnn_model(cnn)\n",
        "\n",
        "\n",
        "  # Compile the model\n",
        "  cnn_model.compile(\n",
        "    # Type here your keras compile specifications\n",
        "  )  \n",
        "  \n",
        "  return cnn_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzbFkAx_x2Qf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from os.path import join\n",
        "from os import makedirs\n",
        "import time\n",
        "\n",
        "\n",
        "def get_callbacks(model_name):\n",
        "  \"\"\"\n",
        "  Instantiates different Keras Callbacks used to analyse and compare training results\n",
        "  \"\"\"\n",
        "  # Define unique training ID such that logging events are stored in a unique folder\n",
        "  model_id = time.strftime('%Y-%m-%d_%H-%M-%S')\n",
        "\n",
        "  \n",
        "  # Callback that saves the model after every epoch\n",
        "  os.makedirs(join(base_dir, 'models'), exist_ok=True)  # create models directory if not already present\n",
        "  callback_model = ModelCheckpoint(filepath=join(base_dir, 'models', f'{model_name}_{model_id}.hdf5'),  # Make sure you save the model in /tmp/models !\n",
        "                                   save_best_only=True, save_weights_only=False  # Make sure you set save_weights_only to FALSE and save_best_only to TRUE! This eases the submitting process\n",
        "                                   # Type here your (extra) callback specifications\n",
        "                                  )\n",
        "  \n",
        "  # Callback that writes a log for TensorBoard, which allows you to visualize dynamic graphs of your training and test metrics\n",
        "  # as well as activation histograms for the different layers in your model. \n",
        "  # (https://www.tensorflow.org/tensorboard/)\n",
        "  callback_tensorboard = TensorBoard(log_dir=join(base_dir, 'logs', f'{model_name}_{model_id}'), \n",
        "                                     # Type here your (extra) callback specifications\n",
        "                                     )\n",
        "\n",
        "  return [callback_model, callback_tensorboard]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjWg_H5hcjc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the pre-trained CNN that will be fine-tuned on roof shapes\n",
        "pre_trained_cnn = ...  # 'vgg16', 'inception' or 'xception'\n",
        "\n",
        "\n",
        "# Build and compile a to be trained cnn model (i.e. includes the model architecture, initial parameters, optimizer, loss and evaluation function)\n",
        "cnn_model = build_compile_cnn(cnn=pre_trained_cnn)\n",
        "\n",
        "\n",
        "# Create corresponding train and validation data generators that specify augmentation rules\n",
        "train_data_gen, vali_data_gen = get_cnn_data_generators(cnn=pre_trained_cnn)\n",
        "\n",
        "\n",
        "# Create generators to generate batches of augmented train data using the flow_from_directory function in Keras\n",
        "train_batch_gen, vali_batch_gen = get_image_batches(train_data_gen, \n",
        "                                                    vali_data_gen, \n",
        "                                                    cnn=pre_trained_cnn)\n",
        "\n",
        "# Create callbacks that log training results\n",
        "callbacks = get_callbacks(model_name=pre_trained_cnn)\n",
        "\n",
        "\n",
        "# Fit the CNN to training and validation data\n",
        "trained_cnn = cnn_model.fit_generator(\n",
        "    # Type here your fit_generator specifications\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQWxHi5qq9UB",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "## 6.   Analysing Training Results\n",
        "\n",
        "Analyse your results using TensorBoard! The rnning the cell below one activates this interactive tool. Make sure that the --log_dir parameter is configured to be directory in which all TensorBoard log event folders (1 folder for each trained model) are stored."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc_zpbIR13Os",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {join(base_dir, 'logs')}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isW_JOYt4Gop",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "--- \n",
        "\n",
        "# 7. Submit your model!\n",
        "\n",
        "Submit your preferred trained cnn by running the code below. Make sure you specify a team name and add the name of the pre-trained basemodel to the sumbit_filename parameter. Of course you are allowed to submit more than 1 model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvXM5QsO6o9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os.path import join\n",
        "import zipfile\n",
        "import pickle\n",
        "import requests\n",
        "\n",
        "# Specify your team name\n",
        "team_name = ...\n",
        "\n",
        "# Specify your trained model that will be submitted; hint: TensorBoard lists all modelnames under 'Runs'\n",
        "submit_model = ... + '.hdf5'  # Type here the modelname of the preferred cnn in String (e.g. 'xception_2019-11-19_13-50-08')\n",
        "path2submit_model = join(base_dir, 'models', submit_model)  # this follows from above defined parameters\n",
        "# If you are not sure how you model is named; run code !ls {join(base_dir, 'models')}\n",
        "\n",
        "# compress model to zipfile\n",
        "with zipfile.ZipFile(f'{path2submit_model}.zip', mode='w') as zf:\n",
        "  zf.write(path2submit_model, compress_type=zipfile.ZIP_DEFLATED)\n",
        "\n",
        "with open('pydata2019/signed_url_dict' + '.pkl', 'rb') as f:\n",
        "  s3 = pickle.load(f)\n",
        "\n",
        "with open(f'{path2submit_model}.zip', 'rb') as f:\n",
        "    files = {'file': (submit_model, f)}\n",
        "    data = {'key': f'models/{team_name}/{submit_model}'}\n",
        "    http_response = requests.post(s3['url'], data=data, files=files)\n",
        "\n",
        "if http_response.status_code == 204:\n",
        "  print('Submission sent!')\n",
        "else:\n",
        "  print('Error occurred! Please try again.')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}